{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab8b277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28bda86",
   "metadata": {},
   "source": [
    "# Image Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35cb34df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the image as a coloured image\n",
    "img1= cv2.imread(\"C:/Users/Open user/Documents/AWARRI collection 2/3_men.jpg\", 1)\n",
    "#print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "852bc4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[60, 60, 60, ..., 57, 58, 53],\n",
       "       [60, 60, 60, ..., 57, 60, 57],\n",
       "       [60, 60, 60, ..., 57, 62, 60],\n",
       "       ...,\n",
       "       [40, 44, 48, ..., 54, 52, 52],\n",
       "       [39, 45, 50, ..., 56, 56, 54],\n",
       "       [41, 47, 52, ..., 56, 59, 58]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the image as a grayscale(black&white) image\n",
    "img2= cv2.imread(\"C:/Users/Open user/Documents/AWARRI collection 2/3_men.jpg\", 0)\n",
    "img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c141355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(img1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f870850e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080, 1920, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2346657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080, 1920)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb593aff",
   "metadata": {},
   "source": [
    "# Image viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9595179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Viewing the coloured image\n",
    "cv2.imshow(\"men\", img1)\n",
    "cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ad7505e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Viewing the black and white image image\n",
    "cv2.imshow(\"men\", img2)\n",
    "cv2.waitKey(2000)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf9cbcb",
   "metadata": {},
   "source": [
    "# Image resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a02fb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resizing the coloured image\n",
    "resized_img= cv2.resize(img1, (300, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "476ca522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"men\", resized_img)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec95103b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c602a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#resizing the black and white image\n",
    "resized_img= cv2.resize(img2, (500, 500))\n",
    "cv2.imshow(\"men\", resized_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e76ecbc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#coloured image\n",
    "resized_img2= cv2.resize(img1, (int(img1.shape[1]/2),int(img1.shape[0]/2)))\n",
    "cv2.imshow(\"men\", resized_img2)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab554118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resized_img2= cv2.resize(img, (int(img.shape[1]*2),int(img.shape[0]*2)))\n",
    "cv2.imshow(\"men\", resized_img2)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baf45a3",
   "metadata": {},
   "source": [
    "# Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a2256dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade= cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "226c1423",
   "metadata": {},
   "outputs": [],
   "source": [
    "image= cv2.imread(\"C:/Users/Open user/Documents/AWARRI collection 2/3_men.jpg\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc818d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080, 1920, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1557e44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the image as a gray scale\n",
    "gray_img= cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8cc7cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 220  200  274  274]\n",
      " [ 789  231  304  304]\n",
      " [1477  253  271  271]]\n"
     ]
    }
   ],
   "source": [
    "#Perform face detection\n",
    "faces= face_cascade.detectMultiScale(gray_img, scaleFactor= 1.05, minNeighbors=5)\n",
    "print(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dcb5c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x, y, w, h in faces:\n",
    "    img= cv2.rectangle(image, (x,y), (x+w, y+h), (0, 255, 0), 3)\n",
    "    resized= cv2.resize(img, (int(img.shape[1]/2),int(img.shape[0]/2)))\n",
    "cv2.imshow(\"face_detection\", resized)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ddca68",
   "metadata": {},
   "source": [
    "# Face detection 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00840512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 287  123   38   38]\n",
      " [ 375  117   63   63]\n",
      " [1007   98   73   73]\n",
      " [ 270  427   62   62]\n",
      " [ 730  425   88   88]\n",
      " [ 183   85   64   64]\n",
      " [ 820   92   65   65]\n",
      " [ 791  242   62   62]\n",
      " [ 810  516  235  235]]\n"
     ]
    }
   ],
   "source": [
    "image2= cv2.imread(\"C:/Users/Open user/Documents/AWARRI collection 2/5_sport_men.jpg\", 1)\n",
    "\n",
    "#Reading the image as a gray scale\n",
    "gray_img2= cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Perform face detection\n",
    "faces2= face_cascade.detectMultiScale(gray_img2, scaleFactor= 1.05, minNeighbors=5)\n",
    "print(faces2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb727753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x, y, w, h in faces2:\n",
    "    img= cv2.rectangle(image2, (x,y), (x+w, y+h), (0, 255, 0), 3)\n",
    "    resized2= cv2.resize(img, (int(img.shape[1]/2),int(img.shape[0]/2)))\n",
    "cv2.imshow(\"face_detection2\", resized2)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34481efa",
   "metadata": {},
   "source": [
    "# Face detection 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "caf5dbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[141 110 434 434]]\n"
     ]
    }
   ],
   "source": [
    "images= cv2.imread(\"C:/Users/Open user/Downloads/Bola-Tinubu-11.webp\", 1)\n",
    "\n",
    "#Reading the image as a gray scale\n",
    "gray_img3= cv2.cvtColor(images, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Perform face detection\n",
    "faces3= face_cascade.detectMultiScale(gray_img3, scaleFactor= 1.05, minNeighbors=5)\n",
    "print(faces3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b702efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x, y, w, h in faces3:\n",
    "    img= cv2.rectangle(images, (x,y), (x+w, y+h), (0, 255, 0), 3)\n",
    "    resized3= cv2.resize(img, (int(img.shape[1]/2),int(img.shape[0]/2)))\n",
    "cv2.imshow(\"face_detection2\", resized3)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "015f995c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[170  49 209 209]]\n"
     ]
    }
   ],
   "source": [
    "image3= cv2.imread(\"C:/Users/Open user/Downloads/Sanwo-Olu-2.jpg\")\n",
    "\n",
    "#Reading the image as a gray scale\n",
    "gray= cv2.cvtColor(image3, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Perform face detection\n",
    "faces4= face_cascade.detectMultiScale(gray, scaleFactor= 1.05, minNeighbors=5)\n",
    "print(faces4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f03c593e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 600, 3)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f60c779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x, y, w, h in faces4:\n",
    "    img= cv2.rectangle(image3, (x,y), (x+w, y+h), (0, 255, 0), 3)\n",
    "    resized4= cv2.resize(img, (int(img.shape[1]/2),int(img.shape[0]/2)))\n",
    "cv2.imshow(\"face_detection2\", resized4)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d25fc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x, y, w, h in faces4:\n",
    "    img= cv2.rectangle(image3, (x,y), (x+w, y+h), (0, 255, 0), 3)\n",
    "cv2.imshow(\"face_detection2\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6224dfdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
